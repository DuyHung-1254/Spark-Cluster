Spark Executor Command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx4096M" "-Dspark.driver.port=39141" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:39141" "--executor-id" "0" "--hostname" "192.168.1.57" "--cores" "4" "--app-id" "app-20230528140127-0016" "--worker-url" "spark://Worker@192.168.1.57:38119" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/05/28 14:01:32 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 49846@duyhung-Inspiron-3593
23/05/28 14:01:32 INFO SignalUtils: Registering signal handler for TERM
23/05/28 14:01:32 INFO SignalUtils: Registering signal handler for HUP
23/05/28 14:01:32 INFO SignalUtils: Registering signal handler for INT
23/05/28 14:01:33 WARN Utils: Your hostname, duyhung-Inspiron-3593 resolves to a loopback address: 127.0.1.1; using 192.168.1.57 instead (on interface wlp3s0)
23/05/28 14:01:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/05/28 14:01:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/05/28 14:01:33 INFO SecurityManager: Changing view acls to: pc1
23/05/28 14:01:33 INFO SecurityManager: Changing modify acls to: pc1
23/05/28 14:01:33 INFO SecurityManager: Changing view acls groups to: 
23/05/28 14:01:33 INFO SecurityManager: Changing modify acls groups to: 
23/05/28 14:01:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/28 14:01:34 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:39141 after 147 ms (0 ms spent in bootstraps)
23/05/28 14:01:35 INFO SecurityManager: Changing view acls to: pc1
23/05/28 14:01:35 INFO SecurityManager: Changing modify acls to: pc1
23/05/28 14:01:35 INFO SecurityManager: Changing view acls groups to: 
23/05/28 14:01:35 INFO SecurityManager: Changing modify acls groups to: 
23/05/28 14:01:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/28 14:01:35 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:39141 after 8 ms (0 ms spent in bootstraps)
23/05/28 14:01:35 INFO DiskBlockManager: Created local directory at /tmp/spark-cecb9c38-fc69-41ce-8834-562f0900940f/executor-02a71ffd-b9f8-41b5-862b-beb3c310a16e/blockmgr-d28bdf37-633d-4dac-9dfa-092187b89b7e
23/05/28 14:01:35 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
23/05/28 14:01:36 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.1.45:39141
23/05/28 14:01:36 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.57:38119
23/05/28 14:01:36 INFO TransportClientFactory: Successfully created connection to /192.168.1.57:38119 after 1 ms (0 ms spent in bootstraps)
23/05/28 14:01:36 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.1.57:38119
23/05/28 14:01:36 INFO ResourceUtils: ==============================================================
23/05/28 14:01:36 INFO ResourceUtils: No custom resources configured for spark.executor.
23/05/28 14:01:36 INFO ResourceUtils: ==============================================================
23/05/28 14:01:36 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
23/05/28 14:01:36 INFO Executor: Starting executor ID 0 on host 192.168.1.57
23/05/28 14:01:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38771.
23/05/28 14:01:36 INFO NettyBlockTransferService: Server created on 192.168.1.57:38771
23/05/28 14:01:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/05/28 14:01:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.1.57, 38771, None)
23/05/28 14:01:36 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
nagerId(0, 192.168.1.57, 38771, None)
