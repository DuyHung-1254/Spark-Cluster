Spark Executor Command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx4096M" "-Dspark.driver.port=39183" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:39183" "--executor-id" "0" "--hostname" "192.168.1.57" "--cores" "8" "--app-id" "app-20230524151830-0003" "--worker-url" "spark://Worker@192.168.1.57:46797" "--resourceProfileId" "0"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/05/24 15:18:31 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 10909@duyhung-Inspiron-3593
23/05/24 15:18:31 INFO SignalUtils: Registering signal handler for TERM
23/05/24 15:18:31 INFO SignalUtils: Registering signal handler for HUP
23/05/24 15:18:31 INFO SignalUtils: Registering signal handler for INT
23/05/24 15:18:31 WARN Utils: Your hostname, duyhung-Inspiron-3593 resolves to a loopback address: 127.0.1.1; using 192.168.1.57 instead (on interface wlp3s0)
23/05/24 15:18:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/05/24 15:18:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/05/24 15:18:31 INFO SecurityManager: Changing view acls to: pc1
23/05/24 15:18:31 INFO SecurityManager: Changing modify acls to: pc1
23/05/24 15:18:31 INFO SecurityManager: Changing view acls groups to: 
23/05/24 15:18:31 INFO SecurityManager: Changing modify acls groups to: 
23/05/24 15:18:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/24 15:18:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:39183 after 102 ms (0 ms spent in bootstraps)
23/05/24 15:18:32 INFO SecurityManager: Changing view acls to: pc1
23/05/24 15:18:32 INFO SecurityManager: Changing modify acls to: pc1
23/05/24 15:18:32 INFO SecurityManager: Changing view acls groups to: 
23/05/24 15:18:32 INFO SecurityManager: Changing modify acls groups to: 
23/05/24 15:18:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/24 15:18:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:39183 after 13 ms (0 ms spent in bootstraps)
23/05/24 15:18:32 INFO DiskBlockManager: Created local directory at /tmp/spark-cf8416d4-b53a-460f-8331-6a386cc4b268/executor-80c2f460-312b-409e-846b-39fd28b96887/blockmgr-7cb78a56-0f7c-4af7-bc85-36263529fa9d
23/05/24 15:18:32 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB
23/05/24 15:18:32 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@192.168.1.45:39183
23/05/24 15:18:32 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.1.57:46797
23/05/24 15:18:32 INFO TransportClientFactory: Successfully created connection to /192.168.1.57:46797 after 2 ms (0 ms spent in bootstraps)
23/05/24 15:18:32 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.1.57:46797
23/05/24 15:18:32 INFO ResourceUtils: ==============================================================
23/05/24 15:18:32 INFO ResourceUtils: No custom resources configured for spark.executor.
23/05/24 15:18:32 INFO ResourceUtils: ==============================================================
23/05/24 15:18:32 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
23/05/24 15:18:32 INFO Executor: Starting executor ID 0 on host 192.168.1.57
23/05/24 15:18:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43671.
23/05/24 15:18:32 INFO NettyBlockTransferService: Server created on 192.168.1.57:43671
23/05/24 15:18:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/05/24 15:18:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.1.57, 43671, None)
23/05/24 15:18:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.1.57, 43671, None)
23/05/24 15:18:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.1.57, 43671, None)
23/05/24 15:18:32 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
23/05/24 15:18:33 INFO CoarseGrainedExecutorBackend: Got assigned task 0
23/05/24 15:18:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
23/05/24 15:18:33 INFO TorrentBroadcast: Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
23/05/24 15:18:33 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:42913 after 8 ms (0 ms spent in bootstraps)
23/05/24 15:18:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 2.2 GiB)
23/05/24 15:18:33 INFO TorrentBroadcast: Reading broadcast variable 1 took 320 ms
23/05/24 15:18:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.1 KiB, free 2.2 GiB)
23/05/24 15:18:33 INFO HadoopRDD: Input split: file:/home/pc1/opt/data/data2M_10c.csv:0+33554432
23/05/24 15:18:33 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
23/05/24 15:18:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 32.6 KiB, free 2.2 GiB)
23/05/24 15:18:33 INFO TorrentBroadcast: Reading broadcast variable 0 took 77 ms
23/05/24 15:18:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 367.5 KiB, free 2.2 GiB)
23/05/24 15:18:34 INFO PythonRunner: Times: total = 913, boot = 395, init = 518, finish = 0
23/05/24 15:18:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2402 bytes result sent to driver
23/05/24 15:18:35 INFO CoarseGrainedExecutorBackend: Got assigned task 1
23/05/24 15:18:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
23/05/24 15:18:35 INFO TorrentBroadcast: Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
23/05/24 15:18:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 2.2 GiB)
23/05/24 15:18:35 INFO TorrentBroadcast: Reading broadcast variable 2 took 40 ms
23/05/24 15:18:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.5 KiB, free 2.2 GiB)
23/05/24 15:18:35 INFO HadoopRDD: Input split: file:/home/pc1/opt/data/data2M_10c.csv:0+33554432
23/05/24 15:18:36 INFO BlockManager: Removing RDD 4
/home/pc1/opt/data/data2M_10c.csv:0+33554432
