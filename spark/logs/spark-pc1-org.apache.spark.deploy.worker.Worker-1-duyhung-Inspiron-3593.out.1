Spark Command: /usr/lib/jvm/java-11-openjdk-amd64/bin/java -cp /home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://192.168.1.45:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
23/05/29 02:43:07 INFO Worker: Started daemon with process name: 2491@duyhung-Inspiron-3593
23/05/29 02:43:07 INFO SignalUtils: Registering signal handler for TERM
23/05/29 02:43:07 INFO SignalUtils: Registering signal handler for HUP
23/05/29 02:43:07 INFO SignalUtils: Registering signal handler for INT
23/05/29 02:43:07 WARN Utils: Your hostname, duyhung-Inspiron-3593 resolves to a loopback address: 127.0.1.1; using 192.168.1.57 instead (on interface wlp3s0)
23/05/29 02:43:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
23/05/29 02:43:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
23/05/29 02:43:08 INFO SecurityManager: Changing view acls to: pc1
23/05/29 02:43:08 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 02:43:08 INFO SecurityManager: Changing view acls groups to: 
23/05/29 02:43:08 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 02:43:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 02:43:09 INFO Utils: Successfully started service 'sparkWorker' on port 40647.
23/05/29 02:43:09 INFO Worker: Worker decommissioning not enabled.
23/05/29 02:43:09 INFO Worker: Starting Spark worker 192.168.1.57:40647 with 8 cores, 6.5 GiB RAM
23/05/29 02:43:09 INFO Worker: Running Spark version 3.4.0
23/05/29 02:43:09 INFO Worker: Spark home: /home/pc1/opt/spark
23/05/29 02:43:09 INFO ResourceUtils: ==============================================================
23/05/29 02:43:09 INFO ResourceUtils: No custom resources configured for spark.worker.
23/05/29 02:43:09 INFO ResourceUtils: ==============================================================
23/05/29 02:43:09 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
23/05/29 02:43:09 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
23/05/29 02:43:09 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://192.168.1.57:8081
23/05/29 02:43:09 INFO Worker: Connecting to master 192.168.1.45:7077...
23/05/29 02:43:10 INFO TransportClientFactory: Successfully created connection to /192.168.1.45:7077 after 235 ms (0 ms spent in bootstraps)
23/05/29 02:43:10 INFO Worker: Successfully registered with master spark://192.168.1.45:7077
23/05/29 02:44:22 INFO Worker: Asked to launch executor app-20230529024422-0000/2 for spark-basic
23/05/29 02:44:23 INFO SecurityManager: Changing view acls to: pc1
23/05/29 02:44:23 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 02:44:23 INFO SecurityManager: Changing view acls groups to: 
23/05/29 02:44:23 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 02:44:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 02:44:23 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx4096M" "-Dspark.driver.port=36745" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:36745" "--executor-id" "2" "--hostname" "192.168.1.57" "--cores" "4" "--app-id" "app-20230529024422-0000" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 02:53:52 INFO Worker: Asked to kill executor app-20230529024422-0000/2
23/05/29 02:53:53 INFO ExecutorRunner: Runner thread for executor app-20230529024422-0000/2 interrupted
23/05/29 02:53:53 INFO ExecutorRunner: Killing process!
23/05/29 02:53:55 INFO Worker: Executor app-20230529024422-0000/2 finished with state KILLED exitStatus 143
23/05/29 02:53:55 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
23/05/29 02:53:55 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529024422-0000, execId=2)
23/05/29 02:53:55 INFO ExternalShuffleBlockResolver: Application app-20230529024422-0000 removed, cleanupLocalDirs = true
23/05/29 02:53:55 INFO Worker: Cleaning up local directories for application app-20230529024422-0000
23/05/29 02:56:42 INFO Worker: Asked to launch executor app-20230529025642-0001/2 for spark-basic
23/05/29 02:56:42 INFO SecurityManager: Changing view acls to: pc1
23/05/29 02:56:42 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 02:56:42 INFO SecurityManager: Changing view acls groups to: 
23/05/29 02:56:42 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 02:56:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 02:56:42 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx5120M" "-Dspark.driver.port=39699" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:39699" "--executor-id" "2" "--hostname" "192.168.1.57" "--cores" "4" "--app-id" "app-20230529025642-0001" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:04:48 INFO Worker: Asked to kill executor app-20230529025642-0001/2
23/05/29 03:04:48 INFO ExecutorRunner: Runner thread for executor app-20230529025642-0001/2 interrupted
23/05/29 03:04:48 INFO ExecutorRunner: Killing process!
23/05/29 03:04:50 INFO Worker: Executor app-20230529025642-0001/2 finished with state KILLED exitStatus 143
23/05/29 03:04:50 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
23/05/29 03:04:50 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529025642-0001, execId=2)
23/05/29 03:04:50 INFO ExternalShuffleBlockResolver: Application app-20230529025642-0001 removed, cleanupLocalDirs = true
23/05/29 03:04:50 INFO Worker: Cleaning up local directories for application app-20230529025642-0001
23/05/29 03:06:07 INFO Worker: Asked to launch executor app-20230529030607-0002/2 for spark-basic
23/05/29 03:06:07 INFO SecurityManager: Changing view acls to: pc1
23/05/29 03:06:07 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 03:06:07 INFO SecurityManager: Changing view acls groups to: 
23/05/29 03:06:07 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 03:06:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 03:06:07 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx5120M" "-Dspark.driver.port=38509" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:38509" "--executor-id" "2" "--hostname" "192.168.1.57" "--cores" "4" "--app-id" "app-20230529030607-0002" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:14:37 INFO Worker: Asked to kill executor app-20230529030607-0002/2
23/05/29 03:14:37 INFO ExecutorRunner: Runner thread for executor app-20230529030607-0002/2 interrupted
23/05/29 03:14:37 INFO ExecutorRunner: Killing process!
23/05/29 03:14:41 INFO Worker: Executor app-20230529030607-0002/2 finished with state KILLED exitStatus 143
23/05/29 03:14:41 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
23/05/29 03:14:41 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529030607-0002, execId=2)
23/05/29 03:14:41 INFO ExternalShuffleBlockResolver: Application app-20230529030607-0002 removed, cleanupLocalDirs = true
23/05/29 03:14:41 INFO Worker: Cleaning up local directories for application app-20230529030607-0002
23/05/29 03:15:45 INFO Worker: Asked to launch executor app-20230529031545-0003/4 for spark-basic
23/05/29 03:15:45 INFO Worker: Asked to launch executor app-20230529031545-0003/5 for spark-basic
23/05/29 03:15:45 INFO Worker: Asked to launch executor app-20230529031545-0003/6 for spark-basic
23/05/29 03:15:45 INFO SecurityManager: Changing view acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing view acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing view acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: Changing view acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 03:15:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 03:15:45 INFO SecurityManager: Changing view acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 03:15:45 INFO SecurityManager: Changing view acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 03:15:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 03:15:45 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx2048M" "-Dspark.driver.port=33367" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:33367" "--executor-id" "4" "--hostname" "192.168.1.57" "--cores" "2" "--app-id" "app-20230529031545-0003" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:15:45 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx2048M" "-Dspark.driver.port=33367" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:33367" "--executor-id" "5" "--hostname" "192.168.1.57" "--cores" "2" "--app-id" "app-20230529031545-0003" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:15:45 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx2048M" "-Dspark.driver.port=33367" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:33367" "--executor-id" "6" "--hostname" "192.168.1.57" "--cores" "2" "--app-id" "app-20230529031545-0003" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:24:57 INFO Worker: Asked to kill executor app-20230529031545-0003/5
23/05/29 03:24:58 INFO Worker: Asked to kill executor app-20230529031545-0003/4
23/05/29 03:24:58 INFO Worker: Asked to kill executor app-20230529031545-0003/6
23/05/29 03:24:58 INFO ExecutorRunner: Runner thread for executor app-20230529031545-0003/6 interrupted
23/05/29 03:24:58 INFO ExecutorRunner: Runner thread for executor app-20230529031545-0003/4 interrupted
23/05/29 03:24:58 INFO ExecutorRunner: Runner thread for executor app-20230529031545-0003/5 interrupted
23/05/29 03:24:58 INFO ExecutorRunner: Killing process!
23/05/29 03:24:58 INFO ExecutorRunner: Killing process!
23/05/29 03:24:58 INFO ExecutorRunner: Killing process!
23/05/29 03:25:02 INFO Worker: Executor app-20230529031545-0003/5 finished with state KILLED exitStatus 143
23/05/29 03:25:02 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 5
23/05/29 03:25:02 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529031545-0003, execId=5)
23/05/29 03:25:03 INFO Worker: Executor app-20230529031545-0003/4 finished with state KILLED exitStatus 143
23/05/29 03:25:03 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 4
23/05/29 03:25:03 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529031545-0003, execId=4)
23/05/29 03:25:03 INFO Worker: Executor app-20230529031545-0003/6 finished with state KILLED exitStatus 143
23/05/29 03:25:03 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 6
23/05/29 03:25:03 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529031545-0003, execId=6)
23/05/29 03:25:03 INFO ExternalShuffleBlockResolver: Application app-20230529031545-0003 removed, cleanupLocalDirs = true
23/05/29 03:25:03 INFO Worker: Cleaning up local directories for application app-20230529031545-0003
23/05/29 03:25:13 INFO Worker: Asked to launch executor app-20230529032513-0004/2 for spark-basic
23/05/29 03:25:13 INFO SecurityManager: Changing view acls to: pc1
23/05/29 03:25:13 INFO SecurityManager: Changing modify acls to: pc1
23/05/29 03:25:13 INFO SecurityManager: Changing view acls groups to: 
23/05/29 03:25:13 INFO SecurityManager: Changing modify acls groups to: 
23/05/29 03:25:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: pc1; groups with view permissions: EMPTY; users with modify permissions: pc1; groups with modify permissions: EMPTY
23/05/29 03:25:13 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-amd64/bin/java" "-cp" "/home/pc1/opt/spark/conf/:/home/pc1/opt/spark/jars/*" "-Xmx5120M" "-Dspark.driver.port=44535" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@192.168.1.45:44535" "--executor-id" "2" "--hostname" "192.168.1.57" "--cores" "4" "--app-id" "app-20230529032513-0004" "--worker-url" "spark://Worker@192.168.1.57:40647" "--resourceProfileId" "0"
23/05/29 03:33:56 INFO Worker: Asked to kill executor app-20230529032513-0004/2
23/05/29 03:33:56 INFO ExecutorRunner: Runner thread for executor app-20230529032513-0004/2 interrupted
23/05/29 03:33:56 INFO ExecutorRunner: Killing process!
23/05/29 03:33:58 INFO Worker: Executor app-20230529032513-0004/2 finished with state KILLED exitStatus 143
23/05/29 03:33:58 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 2
23/05/29 03:33:58 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20230529032513-0004, execId=2)
23/05/29 03:33:58 INFO ExternalShuffleBlockResolver: Application app-20230529032513-0004 removed, cleanupLocalDirs = true
23/05/29 03:33:58 INFO Worker: Cleaning up local directories for application app-20230529032513-0004
23/05/29 03:34:25 INFO Worker: 192.168.1.45:7077 Disassociated !
23/05/29 03:34:25 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
23/05/29 03:34:25 INFO Worker: 192.168.1.45:7077 Disassociated !
23/05/29 03:34:25 INFO Worker: Connecting to master 192.168.1.45:7077...
23/05/29 03:34:25 ERROR Worker: Connection to master failed! Waiting for master to reconnect...
23/05/29 03:34:25 INFO Worker: Not spawning another attempt to register with the master, since there is an attempt scheduled already.
23/05/29 03:34:25 INFO TransportClientFactory: Found inactive connection to /192.168.1.45:7077, creating a new one.
23/05/29 03:34:26 WARN Worker: Failed to connect to master 192.168.1.45:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$1.run(Worker.scala:313)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Failed to connect to /192.168.1.45:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.1.45:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/05/29 03:34:32 INFO Worker: Retrying connection to master (attempt # 1)
23/05/29 03:34:32 INFO Worker: Connecting to master 192.168.1.45:7077...
23/05/29 03:34:32 INFO TransportClientFactory: Found inactive connection to /192.168.1.45:7077, creating a new one.
23/05/29 03:34:33 WARN Worker: Failed to connect to master 192.168.1.45:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:370)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Failed to connect to /192.168.1.45:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.1.45:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/05/29 03:34:39 INFO Worker: Retrying connection to master (attempt # 2)
23/05/29 03:34:39 INFO Worker: Connecting to master 192.168.1.45:7077...
23/05/29 03:34:39 INFO TransportClientFactory: Found inactive connection to /192.168.1.45:7077, creating a new one.
23/05/29 03:34:39 WARN Worker: Failed to connect to master 192.168.1.45:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:370)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Failed to connect to /192.168.1.45:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.1.45:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:829)
23/05/29 03:34:46 INFO Worker: Retrying connection to master (attempt # 3)
23/05/29 03:34:46 INFO Worker: Connecting to master 192.168.1.45:7077...
23/05/29 03:34:46 INFO TransportClientFactory: Found inactive connection to /192.168.1.45:7077, creating a new one.
23/05/29 03:34:48 WARN Worker: Failed to connect to master 192.168.1.45:7077
org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:322)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)
	at org.apache.spark.deploy.worker.Worker$$anon$2.run(Worker.scala:370)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: java.io.IOException: Failed to connect to /192.168.1.45:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:284)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:214)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:226)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:204)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:202)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:198)
	... 4 more
Caused by: io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: /192.168.1.45:7077
Caused by: java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:337)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:334)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:776)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:724)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:650)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:562)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:997)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:829)
